# -*- coding: utf-8 -*-
"""credit_risk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y_PoLeq1hEY7493N_LmAie1nTqHITew3

# Credit Risk Analytics in Financial Services Firm (Study Case: ID/X Partners)

## Table of Content
The layout of this documentation is as follows:
- Business Understanding
- Business Objective
    - Problem Statement
    - Objective
- Data Preparation
    - Import Libraries
    - Import Dataset
    - Features Description
- Data Undertanding
    - Statistical Summary
        - Categorical Features
        - Numerical Features
    - Data Types Information
- Data Preprocessing
    - Create the Target Feature
    - EDA
        - Categorical Features Vs Target Feature
        - Numerical Features Vs Target Feature
        - Total Loan Issued Over Time
        - Calculate Total Loss
    - Data Cleansing
        - Detecting Duplication
        - Detecting Missing Values
- Data Modeling
    - Encoding 
    - Feature Selection
    - Handling Imbalanced Data 
    - Data Splitting
    - Normalization
    - Machine Learning Techniques
        - Decision Tree
        - Random Forest
        - Logistic Regression
        - Extra Trees Classifier
        - LightGBM Classifier
    - Model Evaluation
        - ROC Curves
        - KS Statistic Plot
        - Feature Importances
- Conclusion

## Business Understanding

When the lending company receives a loan application, the company has to decide whether to approve or reject the loans application based on the applicant’s profile (every decision made has a good or bad risk).
- If the applicant is likely to repay the loan, then declining their application will be a business loss to the company. This situation is called a good risk.
- If the applicant is not likely to repay the loan, then approving their application will be a financial loss to the company. This situation is called a bad risk.

The data contains the information about past loans of applicants and whether they labeled as a good risk or not. When a applicant applies for a loan, there are two type of risks, namely:

1. Good risk consists of Fully Paid, Current, and In Grace Period. Applicants with this label are more likely to get their loan approved in the future.
2. Bad Risk consists of Late, Default, and Charged Off. Applicants with this label are unlikely to get their loan approved in the future.

## Business Objective

**Problem Statement**:

Lending loans to ‘bad risk’ applicants is the largest source of financial loss. Credit loss is the amount of money lost by the lender when the applicant refuses to pay or runs away with the money owed.

**Objectives**:

1. Identify patterns that indicate if a person is unlikely to repay the loan or labeled as a bad risk so that it can be used to take action such as rejecting the loan, reducing the amount of loan, lending at a higher interest rate, etc.
3. Implement machine learning algorithms to build predictive model so that the company can automatically predict whether the loan application submitted by the applicant will labeled as a bad risk or not. With this, the company can make a decision to approve or reject the loan application.

## Data Preparation

### Import Libraries
"""

#Data manipulation
import numpy as np
import pandas as pd
from datetime import datetime

#Data visualization
import matplotlib.pyplot as plt
import seaborn as sns
!pip install scikit-plot

#Statistical test
from scipy.stats import chi2_contingency

#Preprocessing
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import MinMaxScaler

#Model
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb

#Cross validation
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold

#Metrics
from sklearn.metrics import roc_auc_score

#Model evaluation
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve
from sklearn.metrics import auc
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import classification_report

# Mount GDrive
from google.colab import drive
drive.mount('/content/drive')

# Ignore warning
import warnings
warnings.filterwarnings("ignore")

"""### Import Dataset"""

# import dataset
df = pd.read_csv('/content/drive/MyDrive/ID X Partners - VIX Rakamin Academy/loan_data_2007_2014.csv', sep=',')
print('This dataset has %d rows dan %d columns.\n' % df.shape)
df.head()

"""There are 75 features and 466,285 rows which contains the information about past loans of applicants.

The `loan_status` feature defines the past loan status of applicants, which is Current, Fully Paid, Charged Off, Late (16-30 days), Late (31-120 days), In Grace Period, and Default. This feature will be the target feature for credit risk prediction analysis.

#### Features Description

| Features | Description |
| :--- | :--- |
| addr_state |	The state provided by the applicant in the loan application|
| annual_inc |	The self-reported annual income provided by the applicant during registration|
| annual_inc_joint |	The combined self-reported annual income provided by the co-applicants during registration|
| application_type |	Indicates whether the loan is an individual application or a joint application with two co-applicants|
| collection_recovery_fee |	Post charge off collection fee|
| collections_12_mths_ex_med |	Number of collections in 12 months excluding medical collections|
| delinq_2yrs | The number of 30+ days past-due incidences of delinquency in the applicant's credit file for the past 2 years|
| desc |	Loan description provided by the applicant|
| dti |	A ratio calculated using the applicant’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the applicant’s self-reported monthly income|
| dti_joint |	A ratio calculated using the co-applicants' total monthly payments on the total debt obligations, excluding mortgages and the requested LC loan, divided by the co-applicants' combined self-reported monthly income|
| earliest_cr_line |	The month the applicant's earliest reported credit line was opened|
| emp_length |	Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years|
| emp_title | 	The job title supplied by the applicant when applying for the loan |
| fico_range_high |	The upper boundary range the applicant’s FICO at loan origination belongs to |
| fico_range_low |	The lower boundary range the applicant’s FICO at loan origination belongs to |
| funded_amnt |	The total amount committed to that loan at that point in time|
| rec | 	The total amount committed by investors for that loan at that point in time |
| grade |	LC assigned loan grade |
| home_ownership |	The home ownership status provided by the applicant during registration. Our values are: RENT, OWN, MORTGAGE, OTHER |
| id |	A unique LC assigned ID for the loan listing |
| initial_list_status |	The initial listing status of the loan. Possible values are – W, F |
| inq_last_6mths |	The number of inquiries in past 6 months (excluding auto and mortgage inquiries) |
| installment |	The monthly payment owed by the applicant if the loan originates |
| int_rate |	Interest Rate on the loan |
| is_inc_v |	Indicates if income was verified by LC, not verified, or if the income source was verified |
| issue_d |	The month which the loan was funded |
| last_credit_pull_d |	The most recent month LC pulled credit for this loan |
| last_fico_range_high |	The upper boundary range the applicant’s last FICO pulled belongs to |
| last_fico_range_low |	The lower boundary range the applicant’s last FICO pulled belongs to |
| last_pymnt_amnt | Last total payment amount received |
| last_pymnt_d |	Last month payment was received |
| loan_amnt |	Last month payment was received |
| loan_status |	Current status of the loan |
| member_id |	A unique LC assigned Id for the applicant member |
| mths_since_last_delinq |	The number of months since the applicant's last delinquency |
| mths_since_last_major_derog |	Months since most recent 90-day or worse rating |
| mths_since_last_record |	The number of months since the last public record |
| next_pymnt_d |	Next scheduled payment date |
| open_acc |	The number of open credit lines in the applicant's credit file |
| out_prncp |	Remaining outstanding principal for total amount funded |
| out_prncp_inv |	Remaining outstanding principal for portion of total amount funded by investors |
| policy_code | publicly available policy_code=1, new products not publicly available policy_code=2 |
| pub_rec |Number of derogatory public records |
| purpose |	A category provided by the applicant for the loan request |
| pymnt_plan |	Indicates if a payment plan has been put in place for the loan |
| recoveries |	post charge off gross recovery |
| revol_bal |	Total credit revolving balance |
| revol_util |	Revolving line utilization rate, or the amount of credit the applicant is using relative to all available revolving credit |
| sub_grade |	LC assigned loan subgrade |
| term |	The number of payments on the loan. Values are in months and can be either 36 or 60 |
| title |	The loan title provided by the applicant |
| total_acc |	The total number of credit lines currently in the applicant's credit file |
| total_pymnt |	Payments received to date for total amount funded |
| total_pymnt_inv |	Payments received to date for portion of total amount funded by investors |
| total_rec_int |	Interest received to date |
| total_rec_late_fee |	Late fees received to date |
| total_rec_prncp |	Principal received to date |
| url |	URL for the LC page with listing data |
| verified_status_joint |	Indicates if the co-applicants' joint income was verified by LC, not verified, or if the income source was verified |
| zip_code |	The first 3 numbers of the zip code provided by the applicant in the loan application |
| open_acc_6m |	Number of open trades in last 6 months |
| open_il_6m |	Number of currently active installment trades |
| open_il_12m |Number of installment accounts opened in past 12 months |
| open_il_24m |	Number of installment accounts opened in past 24 months |
| mths_since_rcnt_il |	Months since most recent installment accounts opened |
| total_bal_il |	Total current balance of all installment accounts |
| il_util |	Ratio of total current balance to high credit/credit limit on all install acct |
| open_rv_12m |	Number of revolving trades opened in past 12 months |
| open_rv_24m |	Number of revolving trades opened in past 24 months |
| max_bal_bc |	Maximum current balance owed on all revolving accounts |
| all_util |	Balance to credit limit on all trades |
| total_rev_hi_lim |  	Total revolving high credit/credit limit |
| inq_fi |	Number of personal finance inquiries |
| total_cu_tl |	Number of finance trades |
| inq_last_12m |	Number of credit inquiries in past 12 months |
| acc_now_delinq |	The number of accounts on which the applicant is now delinquent |
| tot_coll_amt |	Total collection amounts ever owed |
| vtot_cur_bal |	Total current balance of all accounts |

## Data Understanding

### Statistical Summary

#### Numerical Features
"""

num_features = df.select_dtypes(include=['int64', 'float64'])
print('The number of numerical features is {}'.format(num_features.shape[1]))

num_features.describe().transpose()

"""- `Unnamed: 0`, `id`, `member_id` are unique for each row. This features will be removed as because it is not needed for analysis.
- `policy_code` has only one unique value. This feature will be removed because no information can be obtained from the this feature.
- There are 17 features that have missing value. This features will be dealt with in the data clansing section.
"""

# drop unnecessary features
df.drop(['Unnamed: 0', 'member_id', 'policy_code'], inplace=True, axis=1)

"""#### Categorical Features"""

cat_features = df.select_dtypes(include=['object'])
print('The number of categorical features is {}'.format(cat_features.shape[1]))

cat_features.describe().transpose()

"""- `emp_title`, `url` ,`desc`, `title`, `zip_code`, and `addr_state` have many unique values. This features will be removed.
- `application_type` has only one unique value. This feature will be removed because no information can be obtained from the this feature.
"""

# drop unnecessary features
df.drop(['emp_title', 'url', 'desc', 'title', 'zip_code', 'addr_state', 'application_type'], inplace=True, axis=1)

"""### Data Types Information"""

print('Data type before correction:\n')
df.info()

"""- `issue_d`, `earliest_cr_line`, `last_pymnt_d`, `next_pymnt_d`, and `last_credit_pull_d` will be converted to datetime format."""

def date_time(dt):
  if dt.year > 2016:
    dt = dt.replace(year=dt.year-100)
  return dt

# convert string to datetime

df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'], format='%b-%y')
df['earliest_cr_line'] = df['earliest_cr_line'].apply(lambda x: date_time(x))
df['issue_d'] = pd.to_datetime(df['issue_d'], format='%b-%y') 
df['next_pymnt_d'] = pd.to_datetime(df['next_pymnt_d'],format='%b-%y') 
df['last_pymnt_d'] = pd.to_datetime(df['last_pymnt_d'],format='%b-%y')
df['last_credit_pull_d'] = pd.to_datetime(df['last_credit_pull_d'],format='%b-%y')
df[['earliest_cr_line', 'issue_d', 'next_pymnt_d', 'last_pymnt_d', 'last_credit_pull_d']].head()

print('Data type after correction:\n')
df.info()

"""## Data Preprocessing

### Create Target Feature

#### Loan Status Description

- **Fully paid** means the loan has been fully repaid, either at the end of the loan term or earlier because of prepayment.

- **Current** means the applicants is making payments on time.

- **In grace period** is a set number of days after the due date during which payment may be made by the applicants without penalty. The exact number of days is determined by each lending company. During this period no late fees are charged, and the delay cannot result in default or cancellation of the loan or contract. In most cases, payment after the due date but during the grace period does not cause a black mark to be added to the applicants’s credit report.

- **Late** means a payment that has not been made by its cutoff time at the end of its due date. The applicant who is late will usually face some penalties and can be subject to late fees. Failure to repay a loan on time usually has negative implications for an applicant credit status and may cause loan terms to be permanently adjusted.
    - 16-30 days late
    - 31-120 days late


- **Default** means that the applicant have failed to make sufficient payments for an extended period. Lenders will deem a loan in default when applicant haven't paid the minimum required payment for a certain number of months in a row, as detailed in their loan contract. Defaulting will drastically reduce credit score, impact the applicant's ability to receive future credit, and can lead to the seizure of personal property. 

- **Charged Off** means if applicants been delinquent on their credit card or loan payments for several months. This occurs when the applicant has deemed an outstanding debt is uncollectible; this typically follows 180 days or six months of non-payment. In addition, debt payments that fall below the required minimum payment for the period will also be charged off if the debtor does not make up for the shortfall.

Based on the explanation above, I will create a new feature, namely risk status which consists of 2 classes.
1. **Good Risk** class consists of Fully Paid, Current, and In Grace Period. 
    - This selection is based on the rule that if the applicants is in these period, then the applicant's credit score will not be affected or does not cause a black mark to be added to the applicant's credit report. 
    - This class means that if the applicant applies for a loan again and is likely to repay the loan, then not approving the loan results in a loss of business to the company.
    
    
2. **Bad Risk** class consist of Default, Late, and Charged Off. 
    - It is because if the applicants is in this period, it will affect their credit score so that it can impact their ability to receive future credit.
    - This class means that if the applicant applies for a loan again and is not likely to repay the loan, then approving the loan may lead to a financial loss for the company.
"""

# create target feature
df['risk'] = np.where((df['loan_status'] =='Charged Off') | 
                         (df['loan_status'] =='Default') | 
                         (df['loan_status'] =='Late (31-120 days)') | 
                         (df['loan_status'] =='Late (16-30 days)') | 
                         (df['loan_status'] =='Does not meet the credit policy. Status:Charged Off'),'Bad Risk','Good Risk')

"""### Exploratory Data Analysis (EDA)

#### Univariate: The Number of Applicants by Loan Status
"""

# table
loan_group = df.groupby('loan_status').size().reset_index()
loan_group.columns = ['target','total']
loan_group['%'] = round(loan_group['total']*100/sum(loan_group['total']),2)
loan_group.sort_values(by='total', ascending=False)

# visualization
sns.set_style('whitegrid')
fig = plt.figure(figsize = (12,7))
loan_group = df['loan_status'].value_counts().sort_values(ascending=True)
loan_group.plot(kind='barh', color='royalblue', width=0.8)
plt.title('The Number of Applicants based on Loan Status\n', fontsize=14)
plt.ylabel('Status of Loan')
plt.xlabel('Count of Applicants')
plt.show()

"""- There are about 48% which is equal to about 224,226 applicants with loan status of Current, followed by loan status of Fully Paid with 39.6% or equal to 184,739 applicants.

#### Univariate: Target Class Balance
"""

risk_group = df.groupby('risk').size().reset_index()
risk_group.columns = ['target','total']
risk_group['%'] = round(risk_group['total']*100/sum(risk_group['total']),2)
risk_group.sort_values(by='total', ascending=False)

# visualization
sns.set_style('whitegrid')
labels = ['Bad Risk', 'Good Risk']
colors = ['tomato', 'royalblue']
sns.set_palette(sns.color_palette(colors))

fig, ax = plt.subplots(figsize=(6, 6))

patches, texts, pcts = plt.pie(risk_group['total'], labels=labels, autopct='%.2f%%', 
        wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'},
        textprops={'fontsize': 13})

# for each wedge, set the corresponding text label color to the wedge's
# face color.
for i, patch in enumerate(patches):
  texts[i].set_color(patch.get_facecolor())
plt.setp(pcts, color='white', fontweight=600)
plt.setp(texts, fontweight=600)
ax.set_title('Target Class Balance', fontsize=14, fontweight='bold')
plt.tight_layout()

"""- It is observed that this dataset is highly imbalanced with the 11% minority class, i.e Bad Risk and 88% majority class, i.e Good Risk.

#### Bivariate Analysis: Categorical Features
"""

good = df[df['risk'] == 'Good Risk']
bad = df[df['risk'] == 'Bad Risk']

"""##### Bivariate: Risk Status by Term"""

# in general
df['term'].value_counts(normalize=True)

# good risk by term
term_group = good.groupby('term').size().reset_index()
term_group.columns = ['term', 'total']
term_group['%'] = round(term_group['total']*100/sum(term_group['total']),2)
print('Good Risk Status by Term')
term_group.sort_values(by='total', ascending=False)

# bad risk by term
term_group = bad.groupby('term').size().reset_index()
term_group.columns = ['term', 'total']
term_group['%'] = round(term_group['total']*100/sum(term_group['total']),2)
print('Bad Risk Status by Term')
term_group.sort_values(by='total', ascending=False)

# visualization
plt.figure(figsize=(10,5))
colors = ['royalblue', 'tomato']
sns.set_style('whitegrid')
sns.set_palette(sns.color_palette(colors))

fig = sns.countplot(data = df, x='term', hue = 'risk')
plt.title('Risk Status by Term\n', fontsize=12)
plt.xlabel('\nTerm', fontsize=12)

"""- Loan term tell us about the number of payments on the loan.
- There are only two types of loan terms, either 36 months or 60 months. Most of the loans (73%) are shorter, with a term of 36 months.
- Loans with 36 months period are almost twice as likely to bad risk as loans with 60 months period.

##### Bivariate: Risk Status by Verification Status
"""

# in general
df['verification_status'].value_counts(normalize=True)

# good risk by verification status
verify_group = good.groupby(['verification_status']).size().reset_index()
verify_group.columns = ['verification_status', 'total']
verify_group['%'] = round(verify_group['total']*100/sum(verify_group['total']),2)
print('Good Risk Status by Verification Status')
verify_group.sort_values(by='total', ascending=False)

# bad risk by verification status
verify_group = bad.groupby(['verification_status']).size().reset_index()
verify_group.columns = ['verification_status', 'total']
verify_group['%'] = round(verify_group['total']*100/sum(verify_group['total']),2)
print('Bad Risk Status by Verification Status')
verify_group.sort_values(by='total', ascending=False)

# visualization
plt.figure(figsize=(10,5))
colors = ['royalblue', 'tomato']
sns.set_style('whitegrid')
sns.set_palette(sns.color_palette(colors))

fig = sns.countplot(data = df, x='verification_status', hue = 'risk')
plt.title('Risk Status by Verification Status\n', fontsize=12)
plt.xlabel('\nVerification Status', fontsize=12);

"""- Verification status tell us whether the income was verified by the company, not verified, or if the income source was verified.
- Most of the income has had its verified by the company (36%) although 31% were not verified.

##### Bivariate: Risk Status by Payment Plan
"""

# replace
df['pymnt_plan'] = df['pymnt_plan'].replace(['n','y'],['No','Yes'])

good = df[df['risk'] == 'Good Risk']
bad = df[df['risk'] == 'Bad Risk']

# in general
df['pymnt_plan'].value_counts(normalize=True)

# good risk by payment plan
pp_group = good.groupby(['pymnt_plan']).size().reset_index()
pp_group.columns = ['pymnt_plan', 'total']
pp_group['%'] = round(pp_group['total']*100/sum(pp_group['total']),2)
print('Good Risk Status by Payment Plan')
pp_group.sort_values(by='total')

# bad risk by payment plan
pp_group = bad.groupby(['pymnt_plan']).size().reset_index()
pp_group.columns = ['pymnt_plan', 'total']
pp_group['%'] = round(pp_group['total']*100/sum(pp_group['total']),2)
print('Bad Risk Status by Payment Plan')
pp_group.sort_values(by='total')

# visualization
plt.figure(figsize=(10,5))
colors = ['royalblue', 'tomato']
sns.set_style('whitegrid')
sns.set_palette(sns.color_palette(colors))

fig = sns.countplot(data = df, x='pymnt_plan', hue = 'risk')
plt.title('Risk Status by Payment Plan\n', fontsize=12)
plt.xlabel('\nPayment Plan', fontsize=12);

"""- Payment plan indicates if a payment plan has been put in place for the loan.
- Most all of the applicants does not prepare a payment plan for the loan (99%), which means they do not have a clear repayment plan. It's interesting that only 9 applicants prepare a payment plan.

##### Bivariate: Risk Status by Initial List Status
"""

# replace
df['initial_list_status'] = df['initial_list_status'].replace(['w','f'],['Whole Loan','Fractional Loan'])

good = df[df['risk'] == 'Good Risk']
bad = df[df['risk'] == 'Bad Risk']

# in general
df['initial_list_status'].value_counts(normalize=True)

# good risk by initial list status
ils_group = good.groupby(['initial_list_status']).size().reset_index()
ils_group.columns = ['initial_list_status', 'total']
ils_group['%'] = round(ils_group['total']*100/sum(ils_group['total']),2)
print('Good Risk Status by Initial List Status')
ils_group.sort_values(by='total', ascending=False)

# bad risk by initial list status
ils_group = bad.groupby(['initial_list_status']).size().reset_index()
ils_group.columns = ['initial_list_status', 'total']
ils_group['%'] = round(ils_group['total']*100/sum(ils_group['total']),2)
print('Bad Risk Status by Initial List Status')
ils_group.sort_values(by='total', ascending=False)

# visualization
plt.figure(figsize=(10,5))
colors = ['royalblue', 'tomato']
sns.set_style('whitegrid')
sns.set_palette(sns.color_palette(colors))

fig = sns.countplot(data = df, x='initial_list_status', hue = 'risk')
plt.title('Risk Status by Initial List Status\n', fontsize=12)
plt.xlabel('\nInitial List Status', fontsize=12);

"""- Initial list status tell us about the initial listing status of the loan. 
- There are only two types of initial list status, either W (Whole loan) or F (Fractional loan). This has to do with whether the creditor provided the entire loan or if the loan is across multiple creditor.
- Most of the loan is fractional loans (64%).

##### Bivariate: Risk Status by Purpose
"""

# in general
df['purpose'].value_counts(normalize=True)

# good risk by purpose
purpose_group = good.groupby(['purpose']).size().reset_index()
purpose_group.columns = ['purpose', 'total']
purpose_group['%'] = round(purpose_group['total']*100/sum(purpose_group['total']),2)
print('Good Risk by Purpose')
purpose_group.sort_values(by='total', ascending=False)

# bad risk by purpose
purpose_group = bad.groupby(['purpose']).size().reset_index()
purpose_group.columns = ['purpose', 'total']
purpose_group['%'] = round(purpose_group['total']*100/sum(purpose_group['total']),2)
print('Bad Risk by Purpose')
purpose_group.sort_values(by='total', ascending=False)

# visualization
fig, ax = plt.subplots(2, figsize=(10,15))
sns.set_style('whitegrid')

sns.countplot(data = good, y='purpose', 
              color = 'royalblue', 
              order = good['purpose'].value_counts().index, 
              ax=ax[0])
ax[0].set_title('Good Risk by Purpose\n', fontsize=12)

sns.countplot(data = bad, y='purpose',
              color = 'tomato', 
              order = bad['purpose'].value_counts().index, 
              ax=ax[1])
ax[1].set_title('Bad Risk by Purpose\n', fontsize=12)

plt.show()

"""- The purpose feature is a category provided by the applicant's for the loan request. There are 13 categories. 
- There are over half of the loans (58%) were for debt consolidation. Other significant categories were credit card and home improvement.
- Only 0.1% of loans for renewable energy have bad risk status, but 61% of debt consolidation loans have bad risk status.

##### Bivariate: Risk Status by Home Ownership
"""

df['home_ownership'].unique()

# reduce the number of categories of home ownership
def func(row):
    if row['home_ownership'] == 'MORTGAGE':
        val = 'MORTGAGE'
    elif (row['home_ownership'] == 'RENT'):
        val ='RENT'
    elif (row['home_ownership'] == 'OWN'):
        val ='OWN'
    else:
        val ='OTHERS'
    return val

df['home_ownership'] = df.apply(func, axis=1)

"""The **ANY** and **NONE** labels on the `home_ownership` feature can be combined with the **OTHER** label."""

good = df[df['risk'] == 'Good Risk']
bad = df[df['risk'] == 'Bad Risk']

# in general
df['home_ownership'].value_counts(normalize=True)

# good risk by home ownership
ho_group = good.groupby(['home_ownership']).size().reset_index()
ho_group.columns = ['home_ownership', 'total']
ho_group['%'] = round(ho_group['total']*100/sum(ho_group['total']),2)
print('Good Risk Status by Home Ownership')
ho_group.sort_values(by='total', ascending=False)

# bad risk by home ownership
ho_group = bad.groupby(['home_ownership']).size().reset_index()
ho_group.columns = ['home_ownership', 'total']
ho_group['%'] = round(ho_group['total']*100/sum(ho_group['total']),2)
print('Bad Risk Status by Home Ownership')
ho_group.sort_values(by='total', ascending=False)

# visualization
plt.figure(figsize=(10,5))
colors = ['royalblue', 'tomato']
sns.set_style('whitegrid')
sns.set_palette(sns.color_palette(colors))

fig = sns.countplot(data = df, x='home_ownership', hue = 'risk')
plt.title('Risk Status by Home Ownership\n', fontsize=12)
plt.xlabel('\nHome Ownership', fontsize=12)

"""- The home ownership feature is category provided by the applicant's during registration.
- Most applicants have an existing mortgage (50%) or are currently renting a home (40%).
- Applicants who have an existing mortgage or are currently renting a home have a higher probability of bad risk.

##### Bivariate: Risk Status by Grade
"""

# in general
df['grade'].value_counts(normalize=True)

# good risk by grade
grade_group = good.groupby(['grade']).size().reset_index()
grade_group.columns = ['grade', 'total']
grade_group['%'] = round(grade_group['total']*100/sum(grade_group['total']),2)
print('Good Risk by Grade')
grade_group.sort_values(by='total', ascending=False)

# bad risk by grade
grade_group = bad.groupby(['grade']).size().reset_index()
grade_group.columns = ['grade', 'total']
grade_group['%'] = round(grade_group['total']*100/sum(grade_group['total']),2)
print('Good Risk by Grade')
grade_group.sort_values(by='total', ascending=False)

# visualization
fig, ax = plt.subplots(2, figsize=(10,15))
sns.set_style('whitegrid')

sns.countplot(data = good, x='grade', 
              color = 'royalblue', 
              order=sorted(good['grade'].unique()), 
              ax=ax[0])
ax[0].set_title('Good Risk by Grade\n', fontsize=12)

sns.countplot(data = bad, x='grade',
              color = 'tomato', 
              order=sorted(bad['grade'].unique()), 
              ax=ax[1])
ax[1].set_title('Bad Risk by Grade\n', fontsize=12)

plt.show()

"""- Grade feature tell us about assigned loan grade by lending company. There are 7 different grades from A to G. 
- Most of the loans are graded B (29.3%). There are about 72%  loan are graded C and above, and less than 1% of the loans are graded G.

##### Bivariate: Risk Status by Sub-Grade
"""

# in general
df['sub_grade'].value_counts(normalize=True).head()

# good risk by sub-grade
sg_group = good.groupby(['sub_grade']).size().reset_index()
sg_group.columns = ['sub_grade', 'total']
sg_group['%'] = round(sg_group['total']*100/sum(sg_group['total']),2)
print('Good Risk by Sub-Grade')
sg_group.sort_values(by='total', ascending=False)
sg_group.head()

# bad risk by sub-grade
sg_group = bad.groupby(['sub_grade']).size().reset_index()
sg_group.columns = ['sub_grade', 'total']
sg_group['%'] = round(sg_group['total']*100/sum(sg_group['total']),2)
print('Bad Risk by Sub-Grade')
sg_group.sort_values(by='total', ascending=True)
sg_group.head()

# visualization
fig, ax = plt.subplots(2, figsize=(10,15))
sns.set_style('whitegrid')

sns.countplot(data = good, x='sub_grade', 
              color = 'royalblue', 
              order=sorted(good['sub_grade'].unique()),
              ax=ax[0])
ax[0].set_title('Good Risk by Sub-Grade\n', fontsize=12)

sns.countplot(data = bad, x='sub_grade',
              color = 'tomato', 
              order=sorted(bad['sub_grade'].unique()),
              ax=ax[1])
ax[1].set_title('Bad Risk by Sub-Grade\n', fontsize=12)

plt.show()

"""##### Bivariate: Risk Status by Employment Length"""

# in general
df['emp_length'].value_counts(normalize=True)

# good risk by employment length
el_group = good.groupby(['emp_length']).size().reset_index()
el_group.columns = ['emp_length', 'total']
el_group['%'] = round(el_group['total']*100/sum(el_group['total']),2)
print('Good Risk by Employment Length')
el_group.sort_values(by='total', ascending=False).head()

# bad risk by employment length
el_group = bad.groupby(['emp_length']).size().reset_index()
el_group.columns = ['emp_length', 'total']
el_group['%'] = round(el_group['total']*100/sum(el_group['total']),2)
print('Bad Risk by Employment Length')
el_group.sort_values(by='total', ascending=False).head()

# visualization
fig, ax = plt.subplots(2, figsize=(10,15))
sns.set_style('whitegrid')

sns.countplot(data = good, y='emp_length', 
              color = 'royalblue', 
              order = good['emp_length'].value_counts().index, 
              ax=ax[0])
ax[0].set_title('Good Risk by Employment Length\n', fontsize=12)

sns.countplot(data = bad, y='emp_length',
              color = 'tomato', 
              order = bad['emp_length'].value_counts().index, 
              ax=ax[1])
ax[1].set_title('Bad Risk by Employment Length\n', fontsize=12)

plt.show()

"""- There are 11 levels, from < 1 year, 1 year, through to 10+ years.
- Applicant's employment length falls into 2 big class: the most frequent is applicants with 10+ years of experience (33.7%), the other is applicants with < 3 years of working experience (32.3%).

#### Bivariate Analysis: Numerical Features
"""

def plot_var(col_name, full_name, continuous):
    f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,3), dpi=90)
    
    # plot without risk status
    if continuous:
        sns.distplot(df.loc[df[col_name].notnull(), col_name], kde=False, color='royalblue', ax=ax1)
    else:
        sns.countplot(df[col_name], order=sorted(df[col_name].unique()), color='tomato', saturation=1, ax=ax1)
    ax1.set_xlabel(full_name)
    ax1.set_ylabel('Count')
    ax1.set_title(full_name)

    # plot with risk status
    if continuous:
        sns.boxplot(x=col_name, y='risk', data=df, ax=ax2)
        ax2.set_ylabel('')
        ax2.set_title(full_name + ' by Risk Status')
    else:
        bad_rates = df.groupby(col_name)['risk'].value_counts(normalize=True).loc[:,'Bad Risk']
        sns.barplot(x=bad_rates.index, y=bad_rates.values, saturation=1, ax=ax2)
    ax2.set_xlabel(full_name)
    
    plt.tight_layout()

"""##### Bivariate: Risk Status by Loan Amount"""

# in general
df['loan_amnt'].describe()

# breakdown per risk status
df.groupby('risk')['loan_amnt'].describe()

# visualization
plot_var('loan_amnt', 'Loan Amount', continuous=True)

"""- The range of loan amount is from \$500 to \$35,000 with a median of \$12,000.
- The median of the applicants with bad risk is slightly higher than the applicants with good risk. It means bad risk loans tend to have higher loan amounts.

##### Bivariate: Risk Status by Interest Rate
"""

# in general
df['int_rate'].describe()

# breakdown per risk status
df.groupby('risk')['int_rate'].describe()

# visualization
plot_var('int_rate', 'Interest Rate', continuous=True)

"""- The range of interest rates on the loans is from 5.42% to 26.06% with a median of 13.6%
- Bad risk loans tend to have higher interest rates. It means applicants with the high interest rate have a high chance of not being able to repay the loan.

##### Bivariate: Risk Status by Installment
"""

# in general
df['installment'].describe()

# breakdown per risk status
df.groupby('risk')['installment'].describe()

# visualization
plot_var('installment', 'Installment', continuous=True)

"""- The range of installments is from \$15.67 to \$1,409.99 per month with a median of \$379.89 per month.
- The median of the applicants with bad risk is slightly higher than the applicants with good risk. It means bad risk loans tend to have higher installments.

##### Bivariate: Risk Status by Annual Income
"""

# in general
df['annual_inc'].describe()

# breakdown per risk status
df.groupby('risk')['annual_inc'].describe()

# visualization
plot_var('annual_inc', 'Annual Income', continuous=True)

"""- The range of annual income of applicants is from \$1,896 to \$7,500,000 with a median of \$63,000
- It appears that applicants with higher income are more likely to repay their loans.

##### Bivariate: Risk Status by Recoveries
"""

# in general
df['recoveries'].describe()

# breakdown per risk status
df.groupby('risk')['recoveries'].describe()

# visualization
plot_var('recoveries', 'Recoveries', continuous=True)

"""- The range of recoveries is from $0 to \$33,520 with a median of \$0
- The bad risk loans tend to have recoveries value greater than 0. It means applicants with a recoveries value greater than 0 have a high chance of not being able to repay the loans. While applicants who are likely to repay the loan have a recoveries value of 0.

##### Bivariate: Risk Status by Collection Recovery Fee
"""

# in general
df['collection_recovery_fee'].describe()

# breakdown per risk status
df.groupby('risk')['collection_recovery_fee'].describe()

# visualization
plot_var('collection_recovery_fee', 'Collection Recovery Fee', continuous=True)

"""- The range of collection recovery fee is from \$0 to \$7,002 with a median of \$0
- The bad risk loans tend to have collection recovery fee greater than 0. It means applicants with a collection recovery fee greater than 0 have a high chance of not being able to repay the loans. While applicants who are likely to repay the loan have a collection recovery fee of 0.

##### Bivariate: Risk Status by Total Principal Received
"""

# in general
df['total_rec_prncp'].describe()

# breakdown per risk status
df.groupby('risk')['total_rec_prncp'].describe()

# visualization
plot_var('total_rec_prncp', 'Total Principal Received', continuous=True)

"""- The range of total principal received is from \$0 to \$35,000 with a median of \$6,817
- Bad risk loans tend to have lower principal received. It means applicants with low principal received are unlikely to repay the loan.

##### Bivariate: Risk Status by Last Payment Amount
"""

# in general
df['last_pymnt_amnt'].describe()

# breakdown per risk status
df.groupby('risk')['last_pymnt_amnt'].describe()

# visualization
plot_var('last_pymnt_amnt', 'Last Payment Amount', continuous=True)

"""- The range of the last payment amount is from \$0 to \$36,234 with a median of \$545.96
- Bad risk loans tend to have a lower amount of last payment. It means applicants with a low last payment amount are unlikely to repay the loan.

##### The Remaining Numerical Features
"""

num = ['funded_amnt', 'funded_amnt_inv','dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq',
       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp',
       'out_prncp_inv', 'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee','collections_12_mths_ex_med', 
       'mths_since_last_major_derog', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim']

# visualization
fig = plt.figure(figsize=(15,20))

for i in range(0, len(num)):
    plt.subplot(6,4,i+1)
    sns.boxplot(y=df[num[i]], x=df['risk'])
plt.xlabel(num[i])
plt.tight_layout()
plt.show()

"""##### Bivariate: Total Loan Issued Over Time"""

df_copy = df.copy()

df_copy["issue_d_year"] = df_copy["issue_d"].dt.strftime('%Y')
issue_agg = df_copy.groupby(["issue_d_year"])[["id"]].nunique()
issue_agg.rename(columns={"id": "count"}, inplace=True)
issue_agg.reset_index(inplace=True)
issue_agg

def plot_df(df, x, y, title="", xlabel='issue_d_year', ylabel='count', dpi=100):
    plt.figure(figsize=(16,5), dpi=dpi)
    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)
    plt.plot(x, y, color='royalblue', marker='o')
    plt.xticks(rotation=45)
    plt.show()

plot_df(issue_agg, x=issue_agg['issue_d_year'], y=issue_agg["count"], title="Total Loan Issued", xlabel='Year', ylabel = "Count")

"""- Total loans issued increase from year to year. The highest occurred in 2014, with 235,628 loans issued by the lending company.
- The highest increase also occurred from 2013 to 2014, which is 100,873 loan increases.

###### Per Risk Status
"""

# issue by rissk status
issue_risk = df_copy.groupby(['issue_d_year', 'risk'])[["id"]].count()
issue_risk.rename(columns={'id': 'count'}, inplace=True)
issue_risk.reset_index(inplace=True)
issue_risk = issue_risk.pivot(index=['issue_d_year'], columns='risk', values='count').reset_index()
issue_risk = issue_risk.reset_index(drop=True).rename_axis(None, axis=1)
issue_risk

sns.set_style('whitegrid')
fig, ax = plt.subplots(figsize=(10,5))
issue_risk.plot(kind='line', ax=ax, lw=2,
                color=['tomato', 'royalblue'])

ax.set_title('Total Loan Issued by Risk Status\n',
        fontsize=12)
ax.set_xlabel('')
ax.set_ylabel('count')
plt.tight_layout()
plt.show()

def plot_df(df, x, y, title="", xlabel='issue_d_year', ylabel='count', dpi=100):
    plt.figure(figsize=(16,5), dpi=dpi)
    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)
    plt.plot(x, y, color='royalblue', marker='o')
    plt.xticks(rotation=45)
    plt.show()

for i in issue_risk.columns:
  if i != 'issue_d_year':
    plot_df(issue_risk, x=issue_risk['issue_d_year'], y=issue_risk[i], title='Total Loan Issued by Status of ' + i, ylabel = i)

"""- The number of loans that have bad risks also increases from year to year. The highest increase occurred from 2012 to 2013, which is 8,757 increases.

##### Bivariate: Total Credit Line Opened Over Time
"""

df_copy["earliest_cr_line_year"] = df_copy["earliest_cr_line"].dt.strftime('%Y')
cline_agg = df_copy.groupby(["earliest_cr_line_year"])[["id"]].nunique()
cline_agg.rename(columns={"id": "count"}, inplace=True)
cline_agg.reset_index(inplace=True)
cline_agg.sort_values(by='count', ascending=False).head(10)

def plot_df(df, x, y, title="", xlabel='earliest_cr_line_year', ylabel='count', dpi=100):
    plt.figure(figsize=(16,5), dpi=dpi)
    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)
    plt.plot(x, y, color='royalblue', marker='o')
    plt.xticks(rotation=45)
    plt.show()

plot_df(cline_agg, x=cline_agg['earliest_cr_line_year'], y=cline_agg["count"], title="Total Credit Line Opened\n", xlabel='Year', ylabel = "Count")

"""- Highest number occurred in 2000 with 35,539 lines of credit open. However, after that, the number of credit lines opened continued to decrease.

#### Calculate the Total Loss Suffered by the Company
"""

# filter only bad risk loans
bad.head()

# calculate total loan to be paid
def word_strip(x):
  return x.strip()
  
bad['term'] = bad['term'].apply(lambda x: word_strip(x))
bad['term'] = bad['term'].replace(['60 months', '36 months'],[60,36])
bad['must_pay'] = bad['term'] * bad['installment']

"""- `installment` : The monthly payment owed by the applicants if the loan originates.
- `term` : The number of payments on the loan.
"""

# calculate the remaining loan to be paid
bad['remain_pay'] = bad['must_pay'] - (bad['total_pymnt'] + bad['total_rec_late_fee'] + bad['collection_recovery_fee'])

"""- `collection_recovery_fee` : Post charge off collection fee.
- `total_pymnt` : Payments received to date for total amount funded.
- `total_rec_late_fee` : Late fees received to date.
"""

# total applicants and loss
print('The number of applicants is', bad['id'].count())
print('Total loss suffered by the company is', bad['remain_pay'].sum())

"""- In general, the lending company has the possibility to suffer a loss of 687 million from 52,186 applicants."""

bad_copy = bad.copy()

# reduce the number of categories of home ownership
def func(row):
    if row['loan_status'] == 'Charged Off':
        val = 'Charged Off'
    elif (row['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'):
        val ='Charged Off'
    elif (row['loan_status'] == 'Late (16-30 days)'):
        val ='Late'
    elif (row['loan_status'] == 'Late (31-120 days)'):
        val ='Late'
    else:
        val ='Default'
    return val

bad_copy['loan_status'] = bad.apply(func, axis=1)

# total loss per loan status
loss_agg= bad_copy.groupby(['loan_status']).agg({"remain_pay" : 'sum', 'id' : 'count'}).reset_index()
loss_agg.columns = ['loan status','total loss', 'total applicant']
loss_agg['% total loss'] = round(loss_agg['total loss']*100/sum(loss_agg['total loss']),2)
loss_agg['avg loss'] = (loss_agg['total loss'])/(loss_agg['total applicant'])
loss_agg.sort_values(by='total loss', ascending=False)

"""- It is observed that the loan status of charged off is the biggest source of loss (83%) for the lending company.

##### Breakdown: Loan Status of Charged Off

In this period, the applicants have been delinquent on their credit card or loan payments for several months, and the creditor has given up on collecting the money owed by the applicants, which means it is a loss for the lending company. There is no longer a reasonable expectation of further payments on this loan.
"""

bad_co = bad.loc[bad['loan_status'].isin(['Does not meet the credit policy. Status:Charged Off', 'Charged Off'])]
bad_co.sample(3)

# total applicants and loss
print('The number of applicants is', bad_co['id'].count())
print('Total loss suffered by the company is', bad_co['remain_pay'].sum())

"""- The lending company has suffered a loss of 574 million from 43,236 applicants.

##### Breakdown: Loan Status of Late

In this period, the applicants failed to make a timely payment within the grace period. Late payments can hurt applicants credit scores, although the impact will depend on applicants overall credit profile and how far behind applicants fall on their payments.
"""

bad_lt = bad.loc[bad['loan_status'].isin(['Late (31-120 days)', 'Late (16-30 days)'])]
bad_lt.sample(3)

# total applicants and loss
print('The number of applicants is', bad_lt['id'].count())
print('Total loss suffered by the company is', bad_lt['remain_pay'].sum())

"""- The lending company has the potential to suffer losses of around 102 million from 8,118 applicants if the company does not immediately collect the overdue accounts.

##### Breakdown: Loan Status of Default

In this period, the loan agreement has been terminated by the lending company, and the outstanding balance of the loan is due and payable. Defaulting on a loan happens when repayments aren't made for a certain period of time. When a loan defaults, it is sent to a debt collection agency whose job is to contact the applicant and receive the unpaid funds. Defaulting will drastically reduce your credit score, impact your ability to receive future credit, and can lead to the seizure of personal property.
"""

bad_default = bad[bad['loan_status'] == 'Default']
bad_default.sample(3)

# total applicants and loss
print('The number of applicants is', bad_default['id'].count())
print('Total loss suffered by the company is', bad_default['remain_pay'].sum())

"""- The lending company has the potential to suffer losses of around 11 million from 832 applicants if the company does not immediately contact the applicants and receive the unpaid funds.

### Data Cleansing

#### Drop Unnecessary Columns
"""

df.drop(['id'], inplace= True, axis=1)
df.sample(5)

"""#### Detecting Duplication"""

print('Duplication status:', df.duplicated().values.any())
print('The number of duplication is:', df.duplicated().sum())

"""#### Detecting Missing Values"""

# check for missing values
print('Missing values status:', df.isnull().values.any())
mv_percent = df.isnull().sum() * 100 / len(df)
dtypes=[df[col].dtype for col in df.columns]
mv_df = pd.DataFrame({'data type':dtypes,
                                 '%': mv_percent})
mv_df.sort_values('%', ascending=False, inplace=True)
mv_df

# drop features that have large number of missing values (> 50%)
df.drop(df.iloc[:, 47:64], inplace=True, axis=1)
df.drop(['verification_status_joint','dti_joint', 
         'annual_inc_joint', 'mths_since_last_record', 
         'mths_since_last_major_derog', 'mths_since_last_delinq'], inplace=True, axis=1)

# check for missing values
print('Missing values status:', df.isnull().values.any())
mv_percent = df.isnull().sum() * 100 / len(df)
dtypes=[df[col].dtype for col in df.columns]
mv_df = pd.DataFrame({'data type':dtypes,
                                 '%': mv_percent})
mv_df.sort_values('%', ascending=False, inplace=True)
mv_df

# distribution of numerical features that have missing values
sns.set_style('whitegrid')
fig, ax = plt.subplots(3,3, figsize=(20,20))
sns.set_context('paper', font_scale=1)

sns.distplot(df['annual_inc'], ax=ax[0][0])
sns.distplot(df['revol_util'], ax=ax[0][1])
sns.distplot(df['collections_12_mths_ex_med'], ax=ax[0][2])
sns.distplot(df['open_acc'], ax=ax[1][0])
sns.distplot(df['inq_last_6mths'], ax=ax[1][1])
sns.distplot(df['delinq_2yrs'], ax=ax[1][2])
sns.distplot(df['total_acc'], ax=ax[2][0])
sns.distplot(df['pub_rec'], ax=ax[2][1])
sns.distplot(df['acc_now_delinq'], ax=ax[2][2])

"""- The distribution of numerical features that mentioned above is skewed, so the missing values in those features will be imputed with their median."""

# impute missing values with median because the data is skewed for numerical features
# impute missing values with mode for categorical features

cat_columns = df.select_dtypes(include=['object','datetime64[ns]']).columns.tolist()
num_columns = df.select_dtypes(include=['int64','float64']).columns.tolist()

for column in df:
    if df[column].isnull().any():
        if(column in cat_columns):
            df[column]=df[column].fillna(df[column].mode()[0])
        else:
            df[column]=df[column].fillna(df[column].median())

# after imputation
print('Missing values status:', df.isnull().values.any())

"""## Building a Model

### Drop Unnecessary Feature

Drop the loan status feature because it is not needed in the analysis. For prediction will use the risk feature as the target feature.
"""

df.drop(['loan_status'], inplace=True, axis=1)

"""### Create a New Feature from Date Type Features

I will separate these features into days, months and years.
- `issue_d` : The month which the loan was funded.
- `earliest_cr_line` : The month the applicant's earliest reported credit line was opened.
- `last_pymnt_d` : Last month payment was received.
- `next_pymnt_d` : Next scheduled payment date.
- `last_credit_pull_d` : The most recent month LC pulled credit for this loan.
"""

df["issue_d_year"] = df["issue_d"].dt.year
df["issue_d_month"] = df["issue_d"].dt.month
df["issue_d_day"] = df["issue_d"].dt.day

df["earliest_cr_line_year"] = df["earliest_cr_line"].dt.year
df["earliest_cr_line_month"] = df["earliest_cr_line"].dt.month
df["earliest_cr_line_day"] = df["earliest_cr_line"].dt.day

df["last_pymnt_d_year"] = df["last_pymnt_d"].dt.year
df["last_pymnt_d_month"] = df["last_pymnt_d"].dt.month
df["last_pymnt_d_day"] = df["last_pymnt_d"].dt.day

df["next_pymnt_d_year"] = df["next_pymnt_d"].dt.year
df["next_pymnt_d_month"] = df["next_pymnt_d"].dt.month
df["next_pymnt_d_day"] = df["next_pymnt_d"].dt.day

df["last_credit_pull_d_year"] = df["last_credit_pull_d"].dt.year
df["last_credit_pull_d_month"] = df["last_credit_pull_d"].dt.month
df["last_credit_pull_d_day"] = df["last_credit_pull_d"].dt.day

# drop the original
df.drop(['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d'], inplace=True, axis=1)

df.sample(5)

"""### Encoding

There are 2 options in converting categorical features to numeric, namely label encoding and one hot encoding.
1. Apply **One Hot Encoding** when:
    - The categorical feature is not ordinal.
    - The number of categorical features is less so one-hot encoding can be effectively applied.


2. Apply **Label Encoding** when:
    - The categorical feature is ordinal (like Jr. kg, Sr. kg, Primary school, high school)
    - The number of categories is quite large as one-hot encoding can lead to high memory consumption.
"""

df.select_dtypes(include='object').columns.tolist()

"""#### One Hot Encoding

`home_ownership`, `verification_status`, `pymnt_plan`, `purpose`, `initial_list_status` will be encoded using one hot encoding because these features is non-ordinal data.
"""

df_1 = df.drop(['home_ownership', 'verification_status', 'pymnt_plan', 'purpose', 'initial_list_status'], axis=1)
cat_1 = df[['home_ownership', 'verification_status', 'pymnt_plan', 'purpose', 'initial_list_status']]

oho = OneHotEncoder(sparse=False)

df_encoded = pd.DataFrame(oho.fit_transform(cat_1))
df_encoded.columns = oho.get_feature_names(['home_ownership', 'verification_status', 'pymnt_plan', 'purpose', 'initial_list_status'])
concatenated_data = pd.concat([df_1, df_encoded], axis=1)
concatenated_data.sample(5)

"""#### Manual Encoding

`emp_length` feature will be encoded manually because its meaning will change if done with label encoding.
"""

concatenated_data['emp_length'].replace({'< 1 year':0, '1 year':1, '2 years':2,
                                           '3 years':3, '4 years':4, '5 years':5,
                                           '6 years':6, '7 years':7, '8 years':8, 
                                           '9 years':9, '10+ years':10},inplace=True)

"""#### Label Encoding

`term`, `grade`, `sub_grade`, `risk`, `initial_list_status` will be encoded using one hot encoding because these feature is ordinal data.
"""

# convert all non-numeric variables (ordinal) to numeric type
for column in concatenated_data.columns:
    if concatenated_data[column].dtype == np.number: continue
    # perform encoding for each non-numeric variables
    concatenated_data[column] = LabelEncoder().fit_transform(concatenated_data[column])

concatenated_data.head()

"""### Feature Selection"""

corr = concatenated_data.corrwith(concatenated_data["risk"])
corr.reset_index(name='corr value').sort_values('corr value', ascending=False)

"""- The features that have high correlation value with risk status (target feature) is `recoveries`. 
- `collection_recovery_fee`, `total_rec_prncp` , `last_pymnt_d_year`, `total_pymnt_inv`, `total_pymnt`, `last_pymnt_amnt`, `out_prncp`, `out_prncp_inv`, `total_rec_late_fee`, `grade`, `sub_grade`, `int_rate`, `last_credit_pull_d_year` , `last_credit_pull_d_month`, and `last_pymnt_d_month` have low correlation value but the correlation value is still greater than the other features (corr > 0.10).
"""

# let's only include the features mentioned above
fig = plt.figure(figsize = (40,30))
corr_data = concatenated_data[['risk', 'recoveries', 'collection_recovery_fee', 'total_rec_prncp' , 'last_pymnt_d_year', 
                               'total_pymnt_inv', 'total_pymnt', 'last_pymnt_amnt', 'out_prncp', 'out_prncp_inv', 
                               'total_rec_late_fee', 'grade', 'sub_grade', 'int_rate', 'last_pymnt_d_month',
                              'last_credit_pull_d_month', 'last_credit_pull_d_year']]
sns.heatmap(corr_data.corr(),cmap='Blues', annot = True);

"""### Handling Imbalanced Data"""

# define X and y
X = corr_data.drop(['risk'], axis=1) #features
y = corr_data['risk'] #target

"""The risk status is highly imbalanced, with 11% Bad Risk and 88% Good Risk. So for modelling, it will be used **class_weight = 'balanced'** for handling imbalanced target.

**Note**: When apply machine learning algorithms with imbalanced data, the model obtained will be more biased towards the majority classes. It means the model will predict the majority classes instead of the minority classes.

### Data Splitting

Split the data into training set and testing set with proportion of 80:20.
"""

# splitting tha data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train.shape, X_test.shape)

"""### Normalization

Normalization is important because the features have different range of value. 

**Note**: Features that are measured at different scales do not contribute equally to the analysis and might end up creating a bias.
"""

# normalize the data for numerical stability
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

"""### Machine Learning Techniques

Here are some algorithms that will be tested to determine the best model to predict credit risk:
1. Decision Tree
2. Random Forest
3. Logistic Regression
4. Extra Trees Classifier
5. LightGBM Classifier

#### 1. Decision Tree
"""

# train the model
dt_model = DecisionTreeClassifier(class_weight='balanced').fit(X_train,y_train)
print(dt_model)

"""##### Performance of Training Model"""

# predict data train
y_train_pred_dt = dt_model.predict(X_train)

# print classification report
print('Classification Report Training Model (Decision Tree):')
print(classification_report(y_train, y_train_pred_dt))

# form confusion matrix as a dataFrame
confusion_matrix_dt = pd.DataFrame((confusion_matrix(y_train, y_train_pred_dt)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_dt, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Training Model (Decision Tree)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the training model of decision tree algorithms has a very high accuracy value.


Based on **confusion matrix**, it observed that:
- The classifier made a total of 373,028 predictions. But only 372,767 of them were predicted correctly.
- The classifier predicted bad risk 331,021 and good risk 41,746. In reality, risk status in the sample has 41,759 bad risk and 331,269 good risk.
- The decision tree model classified almost 100% of them correctly.

##### Performance of Testing Model
"""

# predict data test
y_test_pred_dt = dt_model.predict(X_test)

# print classification report
print('Classification Report Testing Model (Decision Tree):')
print(classification_report(y_test, y_test_pred_dt))

# form confusion matrix as a dataFrame
confusion_matrix_dt = pd.DataFrame((confusion_matrix(y_test, y_test_pred_dt)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_dt, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBuGn')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Testing Model (Decision Tree)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the testing model of decision tree algorithms has a very high accuracy value.


Based on **confusion matrix**, it observed that:
- The classifier made a total of 93,257 predictions. But only 91,381 of them were predicted correctly.
- The classifier predicted bad risk 9,675 and good risk 81,706. In reality, risk status in the sample has 10,427 bad risk and 82,830 good risk.
- The model classified 97% of them correctly.
"""

acc_dt_train=round(dt_model.score(X_train,y_train)*100,2)
acc_dt_test=round(dt_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_dt_train))
print("Testing Accuracy: {} %".format(acc_dt_test))

"""#### 2. Random Forest"""

# train the model
rf_model = RandomForestClassifier(class_weight='balanced').fit(X_train, y_train)
print(rf_model)

"""##### Performance of Training Model"""

# predict data train
y_train_pred_rf = rf_model.predict(X_train)

# print classification report
print('Classification Report Training Model (Random Forest):')
print(classification_report(y_train, y_train_pred_rf))

# form confusion matrix as a dataFrame
confusion_matrix_rf = pd.DataFrame((confusion_matrix(y_train, y_train_pred_rf)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_rf, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Training Model (Random Forest)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the training model of random forest algorithms has a very high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 373,028 predictions. But only 372,860 of them were predicted correctly.
- The classifier predicted bad risk 41,711 and good risk 331,149. In reality, risk status in the sample has 41,759 bad risk and 331,269 good risk.
- The random forest model classified almost 100% of them correctly.

##### Performance of Testing Model
"""

# predict data test
y_test_pred_rf = rf_model.predict(X_test)

# print classification report
print('Classification Report Testing Model (Random Forest):')
print(classification_report(y_test, y_test_pred_rf))

# form confusion matrix as a dataFrame
confusion_matrix_rf = pd.DataFrame((confusion_matrix(y_test, y_test_pred_rf)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_rf, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBuGn')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Testing Model (Random Forest)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the testing model of random forest algorithms has a very high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 93,257 predictions. But only 92,350 of them were predicted correctly.
- The classifier predicted bad risk 9,665 and good risk 82,685. In reality, risk status in the sample has 10,427 bad risk and 82,830 good risk.
- The random forest model classified 99% of them correctly.
"""

acc_rf_train=round(rf_model.score(X_train,y_train)*100,2)
acc_rf_test=round(rf_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_rf_train))
print("Test Accuracy: {} %".format(acc_rf_test))

"""#### 3. Logistic Regression"""

# train the model
log_model = LogisticRegression(class_weight='balanced').fit(X_train, y_train)
print(log_model)

"""##### Performance of Training Model"""

# predict data train
y_train_pred_log = log_model.predict(X_train)

# print classification report
print('Classification Report Training Model (Logistic Regression):')
print(classification_report(y_train, y_train_pred_log))

# form confusion matrix as a dataFrame
confusion_matrix_log = pd.DataFrame((confusion_matrix(y_train, y_train_pred_log)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_log, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Training Model (Logistic Regression)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the training model of logistic regression algorithms has a high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 373,028 predictions. But only 325,497 of them were predicted correctly.
- The classifier predicted bad risk 36,871 and good risk 288,626. In reality, risk status in the sample has 41,759 bad risk and 331,269 good risk.
- The model classified 87% of them correctly.

##### Performance of Testing Model
"""

# predict data test
y_test_pred_log = log_model.predict(X_test)

# print classification report
print('Classification Report Testing Model (Logistic Regression):')
print(classification_report(y_test, y_test_pred_log))

# form confusion matrix as a dataFrame
confusion_matrix_log = pd.DataFrame((confusion_matrix(y_test, y_test_pred_log)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_log, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBuGn')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Testing Model (Logistic Regression)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the testing model of logistic regression algorithms has a high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 93,257 predictions. But only 79,419 of them were predicted correctly.
- The classifier predicted bad risk 9,461 and good risk 69,958. In reality, risk status in the sample has 10,427 bad risk and 82,830 good risk.
- The logistic regression model classified 85% of them correctly.
"""

acc_log_train=round(log_model.score(X_train,y_train)*100,2)
acc_log_test=round(log_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_log_train))
print("Test Accuracy: {} %".format(acc_log_test))

"""#### 4. Extra Trees Classifier"""

# train the model
etc_model = ExtraTreesClassifier(class_weight='balanced').fit(X_train, y_train)
print(etc_model)

"""##### Performance of Training Model"""

# predict data train
y_train_pred_etc = etc_model.predict(X_train)

# print classification report
print('Classification Report Training Model (Extra Trees Classifier):')
print(classification_report(y_train, y_train_pred_etc))

# form confusion matrix as a dataFrame
confusion_matrix_etc = pd.DataFrame((confusion_matrix(y_train, y_train_pred_etc)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_etc, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Training Model (Extra Trees Classifier)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the training model of extra trees classifier algorithms has a very high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 373,028 predictions. But only 372,767 of them were predicted correctly.
- The classifier predicted bad risk 41,746 and good risk 331,021. In reality, risk status in the sample has 41,759 bad risk and 331,269 good risk.
- The extra trees classifier model classified almost 100% of them correctly.

##### Performance of Testing Model
"""

# predict data test
y_test_pred_etc = etc_model.predict(X_test)

# print classification report
print('Classification Report Testing Model (Extra Trees Classifier):')
print(classification_report(y_test, y_test_pred_etc))

# form confusion matrix as a dataFrame
confusion_matrix_etc = pd.DataFrame((confusion_matrix(y_test, y_test_pred_etc)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_etc, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBuGn')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Testing Model (Extra Trees Classifier)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the testing model of extra trees classifier algorithms has a very high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 93,257 predictions. But only 92,166 of them were predicted correctly.
- The classifier predicted bad risk 9,619 and good risk 82,547. In reality, risk status in the sample has 10,427 bad risk and 82,830 good risk.
- The extra trees classifier model classified almost 98% of them correctly.
"""

acc_etc_train=round(etc_model.score(X_train,y_train)*100,2)
acc_etc_test=round(etc_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_etc_train))
print("Test Accuracy: {} %".format(acc_etc_test))

"""#### 5. LightGBM Classifier"""

# train the model
lgbm_model = lgb.LGBMClassifier(class_weight='balanced').fit(X_train, y_train)

"""##### Performance of Training Model"""

# predict data train
y_train_pred_lgbm = lgbm_model.predict(X_train)

# print classification report
print('Classification Report Training Model (LightGBM Classifier):')
print(classification_report(y_train, y_train_pred_lgbm))

# form confusion matrix as a dataFrame
confusion_matrix_lgbm = pd.DataFrame((confusion_matrix(y_train, y_train_pred_lgbm)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_lgbm, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Training Model (LightGBM Classifier)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the training model of lightgbm classifier algorithms has a very high accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 373,028 predictions. But only 367,378 of them were predicted correctly.
- The classifier predicted bad risk 39,949 and good risk 327,429. In reality, risk status in the sample has 41,759 bad risk and 331,269 good risk.
- The lightgbm classifier model classified 98% of them correctly.

##### Performance of Testing Model
"""

# predict data test
y_test_pred_lgbm = lgbm_model.predict(X_test)

# print classification report
print('Classification Report Testing Model (LightGBM Classifier):')
print(classification_report(y_test, y_test_pred_lgbm))

# form confusion matrix as a dataFrame
confusion_matrix_lgbm = pd.DataFrame((confusion_matrix(y_test, y_test_pred_lgbm)), ('Bad Risk', 'Good Risk'), ('Bad Risk', 'Good Risk'))

# plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_lgbm, annot=True, annot_kws={'size': 13}, fmt='d', cmap='PuBuGn')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

plt.title('Confusion Matrix for Testing Model (LightGBM Classifier)\n', fontsize=13, color='black')
plt.ylabel('True label', fontsize=13)
plt.xlabel('\nPredicted label', fontsize=13)
plt.show()

"""Based on the **classification report** results, the testing model of gradient boosting algorithms has a medium accuracy value.

Based on **confusion matrix**, it observed that:
- The classifier made a total of 93,257 predictions. But only 91,578 of them were predicted correctly.
- The classifier predicted bad risk 9,951 and good risk 81,627 times. In reality, risk status in the sample has 10,427 bad risk and 82,830 good risk.
- The bad risk class and the good risk class are both the best-classified classes. However, the bad risk class is slightly better than the good risk class, the gradient boosting model classified 98% of them correctly.
"""

acc_lgbm_train=round(lgbm_model.score(X_train,y_train)*100,2)
acc_lgbm_test=round(lgbm_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_lgbm_train))
print("Test Accuracy: {} %".format(acc_lgbm_test))

"""### Model Evaluation

The results will be evaluated and compared by looking at ROC-AUC value of each model. ROC-AUC or "Area Under the Curve (AUC) of "Receiver Characteristic Operator” (ROC) is an evaluation metric for binary classification problems. It is a probability curve that plots the True Positive Rate (TPR) against False Positive Rate (FPR) at various threshold values and essentially separates the 'signal' from the 'noise'. The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes.

#### ROC Curves
"""

# Instantiate the classfiers and make a list
model = [lgbm_model, etc_model, rf_model, dt_model, log_model]

# Define a result table as a DataFrame
result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])

# Train the models and record the results
for cls in model:
    yproba = cls.predict_proba(X_test)[::,1]
    
    fpr, tpr, _ = roc_curve(y_test,  yproba)
    auc = roc_auc_score(y_test, yproba)
    
    result_table = result_table.append({'classifiers':cls.__class__.__name__,
                                        'fpr':fpr, 
                                        'tpr':tpr, 
                                        'auc':auc}, ignore_index=True)

# Set name of the classifiers as index labels
result_table.set_index('classifiers', inplace=True)

# Plot the figure
fig = plt.figure(figsize=(8,6))

for i in result_table.index:
    plt.plot(result_table.loc[i]['fpr'], 
             result_table.loc[i]['tpr'], 
             label="{}, AUC={:.3f}".format(i, result_table.loc[i]['auc']))
    
plt.plot([0,1], [0,1], color='orange', linestyle='--')

plt.xticks(np.arange(0.0, 1.1, step=0.1))
plt.xlabel("False Positive Rate", fontsize=15)

plt.yticks(np.arange(0.0, 1.1, step=0.1))
plt.ylabel("True Positive Rate", fontsize=15)

plt.title('ROC Curve Model Comparisons', fontweight='bold', fontsize=15)
plt.legend(prop={'size':13}, loc='lower right')

plt.show()

"""Based on the ROC Curve Model, LightGBM Classifier has the highest AUC score with **0.994**.

#### KS Statistic Plot
"""

import scikitplot as skplt
plt.figure(figsize=(15,10))
y_probas = lgbm_model.fit(X_train, y_train).predict_proba(X_test)

skplt.metrics.plot_ks_statistic(y_test, y_probas)
plt.show();

"""Kolmogorov-Smirnov chart measures performance of classification models. K-S is a measure of the degree of separation between the positive and negative distributions. K-S should be a high value (Max=1.0) when the fit is good and a low value (Min = 0.0) when the fit is not good. When the K-S value goes above 0.05, it means the fit is significant. Based on the graph above, KS value is **0.941**, and it's considered LightGBM Classifier as good performance model.

#### Feature Importances
"""

importances_model = pd.Series(lgbm_model.feature_importances_, index=X.columns).sort_values(ascending=True)

plt.style.use('seaborn-darkgrid')
plt.figure(figsize=(10,10))
fig = importances_model.plot(kind ='barh', color='royalblue', width=0.8)
plt.title('Features Importance Plot\n', fontsize=14)
plt.show()

fig.figure.tight_layout()

"""## Conclusion

1. It concluded that the **LightGBM Classifier** as the best model to predict the loan risk status of the applicants. Compared to the all the models, which have not significant differences in accuracy scores for training and testing data. The difference is LightGBM Classifier has the highest ROC-AUC score compares to the other models.
    
2. The top 3 important features in determining whether an applicant is likely to not repay their loan are the **total principal received**, the **last payment amount**, and the **total payment**. The company needs to monitor these indicators to reduce the risk of loss. In the future, If there are applicants with those indicators, then the company can take action such as rejecting their loan, reducing the amount of the loan, or lending at a higher interest rate to avoid and reduce the total loss suffered by the company.
"""